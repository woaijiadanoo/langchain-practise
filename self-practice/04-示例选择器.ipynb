{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 示例选择器\n",
    "- 根据长度动态选择\n",
    "- 根据语义相似度动态选择\n",
    "- 使用最大边际相关性进行选择"
   ],
   "id": "243f36eab05a231d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T08:22:00.102982Z",
     "start_time": "2025-10-04T08:21:58.710680Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install cohere langchain-cohere langchain-community -i https://pypi.tuna.tsinghua.edu.cn/simple",
   "id": "75a8684baf79429e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: cohere in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (5.18.0)\n",
      "Requirement already satisfied: langchain-cohere in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (0.4.6)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (0.3.30)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from cohere) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.21.2 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from cohere) (0.28.1)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from cohere) (0.4.0)\n",
      "Requirement already satisfied: pydantic>=1.9.2 in c:\\softwares\\python\\miniconda3\\lib\\site-packages (from cohere) (2.11.7)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in c:\\softwares\\python\\miniconda3\\lib\\site-packages (from cohere) (2.33.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from cohere) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from cohere) (0.22.1)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from cohere) (2.32.4.20250913)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in c:\\softwares\\python\\miniconda3\\lib\\site-packages (from cohere) (4.12.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\softwares\\python\\miniconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->cohere) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\softwares\\python\\miniconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->cohere) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\softwares\\python\\miniconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->cohere) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\softwares\\python\\miniconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->cohere) (2025.8.3)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from tokenizers<1,>=0.15->cohere) (0.35.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2025.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\softwares\\python\\miniconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\softwares\\python\\miniconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.67.1)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.76 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from langchain-cohere) (0.3.77)\n",
      "Requirement already satisfied: types-pyyaml<7.0.0.0,>=6.0.12.20240917 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from langchain-cohere) (6.0.12.20250915)\n",
      "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from langchain-community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from langchain-community) (2.0.43)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from langchain-community) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from langchain-community) (2.11.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from langchain-community) (0.4.31)\n",
      "Requirement already satisfied: numpy>=2.1.0 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from langchain-community) (2.3.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (0.3.11)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\softwares\\python\\miniconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.76->langchain-cohere) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\softwares\\python\\miniconda3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<0.4.0,>=0.3.76->langchain-cohere) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\softwares\\python\\miniconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.21.2->cohere) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.21.2->cohere) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\softwares\\python\\miniconda3\\lib\\site-packages (from pydantic>=1.9.2->cohere) (0.6.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\softwares\\python\\miniconda3\\lib\\site-packages (from pydantic>=1.9.2->cohere) (0.4.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\softwares\\python\\miniconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\softwares\\python\\miniconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<2.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\jz292\\appdata\\roaming\\python\\python313\\site-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 根据长度动态选择",
   "id": "49ebc28c65e12090"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T07:41:25.193798Z",
     "start_time": "2025-10-04T07:41:24.664925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 示例：通过计算最终长度，根据输入提示的长度智能地拦截或添加提示。\n",
    "# Example of Intelligently intercepting or adding prompts by calculating the final length based on the length of the input prompts.\n",
    "\n",
    "from langchain_core.example_selectors import LengthBasedExampleSelector\n",
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "\n",
    "# --- 1. 定义示例集 (EXAMPLES) ---\n",
    "\n",
    "# 假设这里有很多提示示例\n",
    "examples = [\n",
    "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
    "    {\"input\": \"tall\", \"output\": \"short\"},\n",
    "    {\"input\": \"sunny\", \"output\": \"gloomy\"},\n",
    "    {\"input\": \"windy\", \"output\": \"calm\"},\n",
    "    {\"input\": \"高兴\", \"output\": \"悲伤\"},\n",
    "]\n",
    "\n",
    "# --- 2. 构建示例模板 (EXAMPLE PROMPT TEMPLATE) ---\n",
    "\n",
    "# 构建单个示例的格式模板\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"输入: {input}\\n反义词: {output}\",\n",
    ")\n",
    "\n",
    "# --- 3. 初始化长度示例选择器 (LENGTH BASED EXAMPLE SELECTOR) ---\n",
    "\n",
    "# 调用长度示例选择器\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    # 传入提示示例组\n",
    "    examples=examples,\n",
    "    # 传入示例模板\n",
    "    example_prompt=example_prompt,\n",
    "    # 设置格式化后的提示的最大长度。如果提示总长超过 25 个“词”，将开始删除示例。\n",
    "    max_length=25,\n",
    "    # 内置get_text_length, 如果默认分词计算方式不满足，可以自己扩展\n",
    "    # 这里我们使用一个简单的基于空格的分词函数来计算长度（词数）。\n",
    "    get_text_length=lambda x: len(x.split()),\n",
    ")\n",
    "\n",
    "# --- 4. 构建动态 FewShot 提示模板 (FEWSHOT PROMPT TEMPLATE) ---\n",
    "\n",
    "# 使用小样本提示模板实现动态示例的调用\n",
    "dynamic_prompt = FewShotPromptTemplate(\n",
    "    # 示例选择器\n",
    "    example_selector=example_selector,\n",
    "    # 示例提示模板\n",
    "    example_prompt=example_prompt,\n",
    "    # 前缀（Instruction）\n",
    "    prefix=\"给出给定的输入的反义词\",\n",
    "    # 后缀，包含用户输入变量\n",
    "    suffix=\"形容词: {adjective}\\n反义词\",\n",
    "    # 传入输入变量\n",
    "    input_variables=[\"adjective\"]\n",
    ")"
   ],
   "id": "8962a4d4a9a84da2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T07:41:39.296884Z",
     "start_time": "2025-10-04T07:41:39.289246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 5. 运行示例 (EXECUTION) ---\n",
    "\n",
    "# 正常长度输入 (短字符串): 应该包含所有或大部分示例，因为总长度不会超过 max_length=25\n",
    "print(\"--- 正常长度输入 (应包含多个示例) ---\")\n",
    "short_string = \"small\"\n",
    "print(dynamic_prompt.format(adjective=short_string))\n",
    "\n",
    "\n",
    "# 过长输入：如果输入长度很长，最终输出将根据长度要求减少示例数量\n",
    "print(\"\\n--- 过长输入 (应减少示例数量) ---\")\n",
    "# 这是一个非常长的字符串，它会占用很多“词数”\n",
    "long_string = \"big and huge adh massive and large and gigantic and tall and much much much much much bigger then everyone\"\n",
    "# 由于输入 'long_string' 太长，它会挤占空间，导致示例被大量删除或全部删除\n",
    "print(dynamic_prompt.format(adjective=long_string))\n",
    "\n",
    "# 可以看到，当输入越长时，为了满足 max_length 的限制，示例的数量就会动态减少。"
   ],
   "id": "ea214f5dbae4e698",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 正常长度输入 (应包含多个示例) ---\n",
      "给出给定的输入的反义词\n",
      "\n",
      "输入: happy\n",
      "反义词: sad\n",
      "\n",
      "输入: tall\n",
      "反义词: short\n",
      "\n",
      "输入: sunny\n",
      "反义词: gloomy\n",
      "\n",
      "输入: windy\n",
      "反义词: calm\n",
      "\n",
      "输入: 高兴\n",
      "反义词: 悲伤\n",
      "\n",
      "形容词: small\n",
      "反义词\n",
      "\n",
      "--- 过长输入 (应减少示例数量) ---\n",
      "给出给定的输入的反义词\n",
      "\n",
      "输入: happy\n",
      "反义词: sad\n",
      "\n",
      "形容词: big and huge adh massive and large and gigantic and tall and much much much much much bigger then everyone\n",
      "反义词\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 根据输入的语义相似度动态选择\n",
    "- 筛选示例组中与输入的语义相似度最高的示例\n",
    "- 本质：将问题与示例嵌入向量空间后进行搜索对比\n",
    "- 依赖：向量数据库"
   ],
   "id": "17bb9946dd25be1c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T09:32:31.678696Z",
     "start_time": "2025-10-04T09:32:31.673347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use the maximum cosine similarity to retrieve relevant examples to make the examples as close as possible to the input\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "import os\n",
    "\n",
    "# 1. Define the base prompt template for a single example\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"输入: {input}\\n反义: {output}\",\n",
    ")\n",
    "\n",
    "# 2. Define the examples for the few-shot learning\n",
    "# Examples of a pretend task of creating antonyms.\n",
    "examples = [\n",
    "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
    "    {\"input\": \"tall\", \"output\": \"short\"},\n",
    "    {\"input\": \"energetic\", \"output\": \"lethargic\"},\n",
    "    {\"input\": \"sunny\", \"output\": \"gloomy\"},\n",
    "    {\"input\": \"windy\", \"output\": \"calm\"}, # Note: Corrected \"cate\" to \"calm\" based on context\n",
    "]"
   ],
   "id": "f2d7c6936f9d9e51",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T09:53:20.289032Z",
     "start_time": "2025-10-04T09:52:26.666862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. Create the Example Selector using Semantic Similarity\n",
    "# Pass in the example group.\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # Pass in the example group.\n",
    "    examples,\n",
    "    # Use hugging face embeddings for similarity search\n",
    "    HuggingFaceEmbeddings(model_name=\"moka-ai/m3e-base\"),\n",
    "    # Use the Chroma vector database to implement the process storage of similar results\n",
    "    FAISS,\n",
    "    # Number of results\n",
    "    k=1,\n",
    ")\n",
    "\n",
    "# 4. Create the final Few-Shot Prompt Template\n",
    "# Pass in the selector and template, as well as the prefix and suffix and input variables\n",
    "similar_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"给出一个输入词的反义词。\",\n",
    "    suffix=\"输入: {adjective}\\n反义:\",\n",
    "    input_variables=[\"adjective\"],\n",
    ")\n",
    "\n",
    "# 5. Test the prompt by passing in a new adjective \"worried\"\n",
    "# Pass in a new adjective, expected output is happy/sad\n",
    "print(similar_prompt.format(adjective=\"worried\"))"
   ],
   "id": "593df4abb477e437",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jz292\\.conda\\envs\\langchain-learning\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\jz292\\.cache\\huggingface\\hub\\models--moka-ai--m3e-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "给出一个输入词的反义词。\n",
      "\n",
      "输入: energetic\n",
      "反义: lethargic\n",
      "\n",
      "输入: worried\n",
      "反义:\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 使用最大边际相关性动态选择示例（MMR）\n",
    "- 筛选示例组中符合MMR规则的示例\n",
    "- 本质：将问题与示例嵌入向量空间后进行搜索比对\n",
    "- 依赖:向量数据库\n",
    "- MMR：是一种在信息检索中常用的方法，它的目标是在相关性和多样性之间找到一个平衡。MMR会首先找出与输入最相似（即余弦相似度最大）的样本。然后在迭代添加样本的过程中，对于与已选择样本过于接近（即相似度过高）的样本惩罚。MMR既能确保选出的样本与输入高度相关，又能保证选出的样本之间有足够的多样性。关注如何在相关性和多样性之间找到一个平衡。"
   ],
   "id": "c2e89a9ce9e35725"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T09:56:42.130151Z",
     "start_time": "2025-10-04T09:56:37.352788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.example_selectors import MaxMarginalRelevanceExampleSelector\n",
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# 设置 API 密钥和基础 URL\n",
    "# 假设您已在环境变量中设置了这些值\n",
    "# api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "# api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# --- 1. 示例数据 ---\n",
    "# 假设有许多 prompt 示例 (输入为形容词，输出为情绪)\n",
    "examples = [\n",
    "    {\"input\": \"happy\", \"output\": \"joy\"},\n",
    "    {\"input\": \"sad\", \"output\": \"grief\"},\n",
    "    {\"input\": \"angry\", \"output\": \"fury\"},\n",
    "    {\"input\": \"calm\", \"output\": \"peace\"},\n",
    "    {\"input\": \"anxious\", \"output\": \"fear\"}, # 新增一个示例\n",
    "    {\"input\": \"gloomy\", \"output\": \"sadness\"}, # 新增一个示例\n",
    "    {\"input\": \"excited\", \"output\": \"anticipation\"}, # 新增一个示例\n",
    "    {\"input\": \"bored\", \"output\": \"apathy\"}, # 新增一个示例\n",
    "]\n",
    "\n",
    "# 构造单个示例的 prompt 模板\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"输入: {input}\\n输出: {output}\",\n",
    ")\n",
    "\n",
    "\n",
    "# --- 2. 创建示例选择器 (MMR) ---\n",
    "\n",
    "# 调用 MMR\n",
    "example_selector = MaxMarginalRelevanceExampleSelector.from_examples(\n",
    "    # 传入示例列表\n",
    "    examples,\n",
    "    # 使用 OpenAI 的 embedding 进行相似性搜索\n",
    "    # 假设您已经配置了 OPENAI_API_BASE 和 OPENAI_API_KEY\n",
    "    HuggingFaceEmbeddings(model_name=\"moka-ai/m3e-base\"),\n",
    "    # 设置使用 FAISS 作为向量数据库\n",
    "    vectorstore_cls=FAISS,\n",
    "    # 返回结果的数量\n",
    "    k=2\n",
    ")\n",
    "\n",
    "# --- 3. 创建 FewShotPromptTemplate ---\n",
    "\n",
    "# MMR Prompt 模板\n",
    "mmr_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    # prompt 的前缀\n",
    "    prefix=\"你是一个情感分析模型，请根据输入的形容词，输出最符合的情绪。\",\n",
    "    # prompt 的后缀/新的输入\n",
    "    suffix=\"\\n请根据上面的示例，为下一个形容词找到对应的情绪：\\n输入: {adjective}\\n输出:\",\n",
    "    # 新的输入变量名\n",
    "    input_variables=[\"adjective\"],\n",
    ")\n",
    "\n",
    "# --- 4. 测试 ---\n",
    "\n",
    "# 当我们输入一个描述情绪的词时，它应该选择最相似的两个示例来填充 prompt\n",
    "# 比如输入 'terrified' (极度恐惧), 应该会选择 'anxious' 和 'angry' (取决于 embedding 的相似度计算)\n",
    "print(\"--- 针对 'terrified' 的完整 prompt ---\")\n",
    "print(mmr_prompt.format(adjective=\"terrified\"))\n",
    "\n",
    "# 再试一个 'joyful' (快乐的)\n",
    "print(\"\\n--- 针对 'joyful' 的完整 prompt ---\")\n",
    "print(mmr_prompt.format(adjective=\"joyful\"))"
   ],
   "id": "bccdbecba721653c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 针对 'terrified' 的完整 prompt ---\n",
      "你是一个情感分析模型，请根据输入的形容词，输出最符合的情绪。\n",
      "\n",
      "输入: anxious\n",
      "输出: fear\n",
      "\n",
      "输入: sad\n",
      "输出: grief\n",
      "\n",
      "\n",
      "请根据上面的示例，为下一个形容词找到对应的情绪：\n",
      "输入: terrified\n",
      "输出:\n",
      "\n",
      "--- 针对 'joyful' 的完整 prompt ---\n",
      "你是一个情感分析模型，请根据输入的形容词，输出最符合的情绪。\n",
      "\n",
      "输入: happy\n",
      "输出: joy\n",
      "\n",
      "输入: anxious\n",
      "输出: fear\n",
      "\n",
      "\n",
      "请根据上面的示例，为下一个形容词找到对应的情绪：\n",
      "输入: joyful\n",
      "输出:\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
