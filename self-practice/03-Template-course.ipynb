{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Template 学习",
   "id": "28bbbe8941c1f1bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T14:21:44.074275Z",
     "start_time": "2025-10-02T14:21:43.644253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 字符模板\n",
    "# string template\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"你是一个{name}，帮我起1个具有{county}特色的{sex}名字\")\n",
    "prompts = prompt.format(name=\"算命大师\", county=\"法国\", sex=\"女孩\")\n",
    "print(prompts)"
   ],
   "id": "6570b4ee007c4f5f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是一个算命大师，帮我起1个具有法国特色的女孩名字\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T14:28:43.135603Z",
     "start_time": "2025-10-02T14:28:43.072488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 对话模板具有结构，chatmodels\n",
    "# chat template with structure\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个起名大师，你的名字叫{name}。\"),\n",
    "    (\"human\", \"你好{name},你感觉如何？\"),\n",
    "    (\"ai\", \"你好！我叫什么名字？\"),\n",
    "    (\"human\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "chats = chat_template.format_messages(name=\"陈大师\", user_input=\"你的爸爸是谁呢？\")\n",
    "print(chats)"
   ],
   "id": "a14535692a93c1b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='你是一个起名大师，你的名字叫陈大师。', additional_kwargs={}, response_metadata={}), HumanMessage(content='你好陈大师,你感觉如何？', additional_kwargs={}, response_metadata={}), AIMessage(content='你好！我叫什么名字？', additional_kwargs={}, response_metadata={}), HumanMessage(content='你的爸爸是谁呢？', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T14:33:01.574849Z",
     "start_time": "2025-10-02T14:33:01.553617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个厉害的人工智能助手\"),\n",
    "    MessagesPlaceholder(\"msgs\")\n",
    "    # \"placeholder\", \"(msgs)\"\n",
    "])\n",
    "\n",
    "result = prompt_template.invoke({\"msgs\": [HumanMessage(content=\"hi!\")]})\n",
    "\n",
    "print(result)"
   ],
   "id": "e84bfed7353cfdc9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='你是一个厉害的人工智能助手', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T14:37:30.161878Z",
     "start_time": "2025-10-02T14:37:30.155812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# 创建系统消息\n",
    "system_message = SystemMessage(\n",
    "    content=\"你是一个有用的助手\",\n",
    "    additional_kwargs={\"大师姓名\":\"陈瞎子\"}\n",
    ")\n",
    "\n",
    "# 创建人类消息\n",
    "human_message = HumanMessage(content=\"hi!\")\n",
    "\n",
    "# 创建AI消息\n",
    "ai_message = AIMessage(content=\"我有什么可以帮助你的？\")\n",
    "\n",
    "[system_message, human_message, ai_message]\n",
    "# 打印消息内容\n",
    "# print(system_message)\n",
    "# print(human_message)\n",
    "# print(ai_message)"
   ],
   "id": "cb5709321b1f0d94",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='你是一个有用的助手', additional_kwargs={'大师姓名': '陈瞎子'}, response_metadata={}),\n",
       " HumanMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='我有什么可以帮助你的？', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T14:47:42.553738Z",
     "start_time": "2025-10-02T14:47:36.328123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#函数大师：根据函数名称，查找函数代码，并给出中文的代码说明\n",
    "# Function Master: Given a function name, find the function code and provide a Chinese code explanation\n",
    "from langchain_core.prompts import StringPromptTemplate\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "# 导入环境变量加载工具\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 加载.env文件中的环境变量\n",
    "load_dotenv()\n",
    "\n",
    "#定义一个简单的函数作为示例效果\n",
    "# Define a simple function as an example\n",
    "def hello_world(abc):\n",
    "    print(\"hello, world!\")\n",
    "    return abc\n",
    "\n",
    "\n",
    "PROMPT = \"\"\"\\\n",
    "你是一个非常有经验和天赋的程序员，现在给你如下函数名称，你会按照如下格式，输出这段代码的名称、源代码、中文解释。\n",
    "函数名称：{function_name}\n",
    "源代码：\n",
    "{source_code}\n",
    "代码解释：\n",
    "\"\"\"\n",
    "\n",
    "import inspect\n",
    "\n",
    "\n",
    "def get_source_code(function_name):\n",
    "    #获得源代码\n",
    "    # Get the source code\n",
    "    return inspect.getsource(function_name)\n",
    "\n",
    "#自定义的模板class\n",
    "# Custom template class\n",
    "class CustomPrompt(StringPromptTemplate):\n",
    "\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        #获得源代码\n",
    "        # Get the source code 获得函数名\n",
    "        source_code = get_source_code(kwargs[\"function_name\"])\n",
    "\n",
    "        #生成提示词模板\n",
    "        # Generate the prompt template\n",
    "        prompt = PROMPT.format(\n",
    "            function_name=kwargs[\"function_name\"], source_code=source_code\n",
    "        )\n",
    "\n",
    "        return prompt\n",
    "\n",
    "\n",
    "#使用自定义的提示词模板，而不是类似对话提示词模板\n",
    "a = CustomPrompt(input_variables=[\"function_name\"])\n",
    "\n",
    "pm = a.format(function_name=hello_world)\n",
    "print(\"格式化之后的提示词为====\")\n",
    "print(pm)\n",
    "\n",
    "#和LLM连接起来\n",
    "# Connect to LLM\n",
    "# 创建DeepSeek 聊天模型实例\n",
    "llm = ChatDeepSeek(\n",
    "    temperature=0,  # temperature=0表示输出更加确定性，不会随机性太强\n",
    "    model_name=\"deepseek-chat\",  # 模型名称\n",
    "    api_key=os.getenv(\"DEEPSEEK_API_KEY\")  # 从环境变量中获取API密钥\n",
    ")\n",
    "\n",
    "msg = llm.invoke(pm)\n",
    "print(msg.content)"
   ],
   "id": "d0df5586da26ee09",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "格式化之后的提示词为====\n",
      "你是一个非常有经验和天赋的程序员，现在给你如下函数名称，你会按照如下格式，输出这段代码的名称、源代码、中文解释。\n",
      "函数名称：<function hello_world at 0x000002191A375C60>\n",
      "源代码：\n",
      "def hello_world(abc):\n",
      "    print(\"hello, world!\")\n",
      "    return abc\n",
      "\n",
      "代码解释：\n",
      "\n",
      "- **函数名称**：`hello_world`\n",
      "\n",
      "- **源代码**：\n",
      "```python\n",
      "def hello_world(abc):\n",
      "    print(\"hello, world!\")\n",
      "    return abc\n",
      "```\n",
      "\n",
      "- **中文解释**：\n",
      "  1. 这是一个名为 `hello_world` 的函数，接受一个参数 `abc`\n",
      "  2. 函数执行时会打印固定字符串 \"hello, world!\" 到控制台\n",
      "  3. 最后将传入的参数 `abc` 原样返回给调用者\n",
      "  4. 函数本身不改变输入参数的值，只是在其前后添加了打印操作\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T14:55:07.673271Z",
     "start_time": "2025-10-02T14:55:03.239244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# zeroshot 会导致低质量回答\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "# 导入环境变量加载工具\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 加载.env文件中的环境变量\n",
    "load_dotenv()\n",
    "\n",
    "# 创建DeepSeek 聊天模型实例\n",
    "llm = ChatDeepSeek(\n",
    "    temperature=0,  # temperature=0表示输出更加确定性，不会随机性太强\n",
    "    model_name=\"deepseek-chat\",  # 模型名称\n",
    "    api_key=os.getenv(\"DEEPSEEK_API_KEY\")  # 从环境变量中获取API密钥\n",
    ")\n",
    "\n",
    "res = llm.invoke(\"What is 2 √ 9?\")\n",
    "print(res.content)"
   ],
   "id": "44ce816482b6d55e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's break this down.\n",
      "\n",
      "The expression is:\n",
      "\n",
      "\\[\n",
      "2 \\sqrt{9}\n",
      "\\]\n",
      "\n",
      "1. First, compute \\(\\sqrt{9}\\):\n",
      "\\[\n",
      "\\sqrt{9} = 3\n",
      "\\]\n",
      "because \\(3^2 = 9\\).\n",
      "\n",
      "2. Then multiply:\n",
      "\\[\n",
      "2 \\times 3 = 6\n",
      "\\]\n",
      "\n",
      "So the answer is:\n",
      "\n",
      "\\[\n",
      "\\boxed{6}\n",
      "\\]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T15:08:38.023659Z",
     "start_time": "2025-10-02T15:08:36.743013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "# 导入环境变量加载工具\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 加载.env文件中的环境变量\n",
    "load_dotenv()\n",
    "\n",
    "# 创建DeepSeek 聊天模型实例\n",
    "model = ChatDeepSeek(\n",
    "    temperature=0,  # temperature=0表示输出更加确定性，不会随机性太强\n",
    "    model_name=\"deepseek-chat\",  # 模型名称\n",
    "    api_key=os.getenv(\"DEEPSEEK_API_KEY\")  # 从环境变量中获取API密钥\n",
    ")\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "\n",
    "# 增加示例组\n",
    "examples = [\n",
    "    {\"input\": \"2 √ 2\", \"output\": \"4\"},\n",
    "    {\"input\": \"2 √ 3\", \"output\": \"5\"},\n",
    "]\n",
    "# 构造提示词模板\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "# 组合示例与提示词\n",
    "few_Shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "# 打印提示词模板\n",
    "print(few_Shot_prompt.invoke({}).to_messages())\n",
    "\n",
    "# 最终提示词\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是一位神奇的数学奇才\"),\n",
    "        few_Shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 重新提问\n",
    "chain = final_prompt | model\n",
    "result = chain.invoke({\"input\": \"What is 2 √ 9?\"})\n",
    "print(result.content)\n",
    "#\n",
    "# res = model.invoke(\"What is 2 √ 9?\")\n",
    "# print(res)\n",
    "# #增加示例\n",
    "# #使用FewShotChatMessagePromptTemplate\n",
    "# from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "# #增加示例组\n",
    "# examples = [\n",
    "#     {\"input\": \"2 √ 2\", \"output\": \"4\"},\n",
    "#     {\"input\": \"2 √ 3\", \"output\": \"5\"},\n",
    "# ]\n",
    "# #构造提示词模板\n",
    "# example_prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\"human\", \"{input}\"),\n",
    "#         (\"ai\", \"{output}\"),\n",
    "#     ]\n",
    "# )\n",
    "# #组合示例与提示词\n",
    "# few_Shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "#     example_prompt=example_prompt,\n",
    "#     examples=examples,\n",
    "# )\n",
    "# #打印提示词模板\n",
    "# print(\"组合之后的提示词为===）\")\n",
    "# print(few_Shot_prompt.invoke({}).to_messages())"
   ],
   "id": "8d917a09c301cded",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='2 √ 2', additional_kwargs={}, response_metadata={}), AIMessage(content='4', additional_kwargs={}, response_metadata={}), HumanMessage(content='2 √ 3', additional_kwargs={}, response_metadata={}), AIMessage(content='5', additional_kwargs={}, response_metadata={})]\n",
      "6\n"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
