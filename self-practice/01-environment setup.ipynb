{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-30T12:44:39.661676Z",
     "start_time": "2025-09-30T12:43:24.220300Z"
    }
   },
   "source": "! pip install langchain dotenv",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
      "  Downloading langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.4.31-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.43-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langchain) (6.0.3)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.2.4-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Collecting orjson>=3.9.14 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading orjson-3.11.3-cp312-cp312-win_amd64.whl.metadata (43 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.25.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.5/1.0 MB 209.7 kB/s eta 0:00:03\n",
      "   -------------------- ------------------- 0.5/1.0 MB 209.7 kB/s eta 0:00:03\n",
      "   -------------------- ------------------- 0.5/1.0 MB 209.7 kB/s eta 0:00:03\n",
      "   -------------------- ------------------- 0.5/1.0 MB 209.7 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 0.8/1.0 MB 241.4 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 0.8/1.0 MB 241.4 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 0.8/1.0 MB 241.4 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 0.8/1.0 MB 241.4 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 0.8/1.0 MB 241.4 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 0.8/1.0 MB 241.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 225.0 kB/s  0:00:05\n",
      "Downloading langchain_core-0.3.76-py3-none-any.whl (447 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
      "Downloading pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 188.6 kB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 188.6 kB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 188.6 kB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 188.6 kB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 188.6 kB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 188.6 kB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 197.4 kB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 197.4 kB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 197.4 kB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 197.4 kB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 197.4 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 1.0/2.0 MB 204.6 kB/s eta 0:00:05\n",
      "   --------------------- ------------------ 1.0/2.0 MB 204.6 kB/s eta 0:00:05\n",
      "   --------------------- ------------------ 1.0/2.0 MB 204.6 kB/s eta 0:00:05\n",
      "   --------------------- ------------------ 1.0/2.0 MB 204.6 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 1.3/2.0 MB 232.2 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 1.6/2.0 MB 273.2 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 1.8/2.0 MB 307.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 329.5 kB/s  0:00:05\n",
      "Downloading sqlalchemy-2.0.43-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.1 MB 985.5 kB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.8/2.1 MB 932.9 kB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.0/2.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.0/2.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.0/2.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.3/2.1 MB 737.4 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.3/2.1 MB 737.4 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 1.8/2.1 MB 883.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 889.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 890.2 kB/s  0:00:02\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading greenlet-3.2.4-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Downloading langsmith-0.4.31-py3-none-any.whl (386 kB)\n",
      "Downloading orjson-3.11.3-cp312-cp312-win_amd64.whl (131 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading zstandard-0.25.0-cp312-cp312-win_amd64.whl (506 kB)\n",
      "Installing collected packages: zstandard, typing-inspection, tenacity, pydantic-core, orjson, jsonpatch, greenlet, annotated-types, SQLAlchemy, requests-toolbelt, pydantic, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "\n",
      "   ---------- -----------------------------  4/15 [orjson]\n",
      "   ---------------- -----------------------  6/15 [greenlet]\n",
      "   --------------------- ------------------  8/15 [SQLAlchemy]\n",
      "   --------------------- ------------------  8/15 [SQLAlchemy]\n",
      "   --------------------- ------------------  8/15 [SQLAlchemy]\n",
      "   --------------------- ------------------  8/15 [SQLAlchemy]\n",
      "   --------------------- ------------------  8/15 [SQLAlchemy]\n",
      "   --------------------- ------------------  8/15 [SQLAlchemy]\n",
      "   --------------------- ------------------  8/15 [SQLAlchemy]\n",
      "   --------------------- ------------------  8/15 [SQLAlchemy]\n",
      "   --------------------- ------------------  8/15 [SQLAlchemy]\n",
      "   --------------------- ------------------  8/15 [SQLAlchemy]\n",
      "   --------------------- ------------------  8/15 [SQLAlchemy]\n",
      "   --------------------- ------------------  8/15 [SQLAlchemy]\n",
      "   ------------------------ ---------------  9/15 [requests-toolbelt]\n",
      "   -------------------------- ------------- 10/15 [pydantic]\n",
      "   -------------------------- ------------- 10/15 [pydantic]\n",
      "   -------------------------- ------------- 10/15 [pydantic]\n",
      "   ----------------------------- ---------- 11/15 [langsmith]\n",
      "   ----------------------------- ---------- 11/15 [langsmith]\n",
      "   -------------------------------- ------- 12/15 [langchain-core]\n",
      "   -------------------------------- ------- 12/15 [langchain-core]\n",
      "   -------------------------------- ------- 12/15 [langchain-core]\n",
      "   -------------------------------- ------- 12/15 [langchain-core]\n",
      "   -------------------------------- ------- 12/15 [langchain-core]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ---------------------------------------- 15/15 [langchain]\n",
      "\n",
      "Successfully installed SQLAlchemy-2.0.43 annotated-types-0.7.0 greenlet-3.2.4 jsonpatch-1.33 langchain-0.3.27 langchain-core-0.3.76 langchain-text-splitters-0.3.11 langsmith-0.4.31 orjson-3.11.3 pydantic-2.11.9 pydantic-core-2.33.2 requests-toolbelt-1.0.0 tenacity-9.1.2 typing-inspection-0.4.1 zstandard-0.25.0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T12:45:46.330577Z",
     "start_time": "2025-09-30T12:45:45.718081Z"
    }
   },
   "cell_type": "code",
   "source": "! pip show langchain",
   "id": "3df1ed5910eacc3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.3.27\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: C:\\Users\\jz292\\.conda\\envs\\langchain-learning\\Lib\\site-packages\n",
      "Requires: langchain-core, langchain-text-splitters, langsmith, pydantic, PyYAML, requests, SQLAlchemy\n",
      "Required-by: \n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T12:59:03.825028Z",
     "start_time": "2025-09-30T12:58:34.527930Z"
    }
   },
   "cell_type": "code",
   "source": "! pip install langchain-deepseek",
   "id": "44d1378dc42d3352",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-deepseek\n",
      "  Downloading langchain_deepseek-0.1.4-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.70 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langchain-deepseek) (0.3.76)\n",
      "Collecting langchain-openai<1.0.0,>=0.3.28 (from langchain-deepseek)\n",
      "  Downloading langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (0.4.31)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (6.0.3)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (25.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (2.11.9)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (3.0.0)\n",
      "Collecting openai<2.0.0,>=1.104.2 (from langchain-openai<1.0.0,>=0.3.28->langchain-deepseek)\n",
      "  Downloading openai-1.109.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai<1.0.0,>=0.3.28->langchain-deepseek)\n",
      "  Downloading tiktoken-0.11.0-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from openai<2.0.0,>=1.104.2->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (4.11.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.104.2->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from openai<2.0.0,>=1.104.2->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.104.2->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek)\n",
      "  Downloading jiter-0.11.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from openai<2.0.0,>=1.104.2->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (1.3.1)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.104.2->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.104.2->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (0.4.1)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek)\n",
      "  Downloading regex-2025.9.18-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (2.32.5)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (0.25.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.104.2->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (0.4.6)\n",
      "Downloading langchain_deepseek-0.1.4-py3-none-any.whl (7.4 kB)\n",
      "Downloading langchain_openai-0.3.33-py3-none-any.whl (74 kB)\n",
      "Downloading openai-1.109.1-py3-none-any.whl (948 kB)\n",
      "   ---------------------------------------- 0.0/948.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/948.6 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/948.6 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/948.6 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 786.4/948.6 kB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 948.6/948.6 kB 1.2 MB/s  0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.11.0-cp312-cp312-win_amd64.whl (203 kB)\n",
      "Downloading tiktoken-0.11.0-cp312-cp312-win_amd64.whl (884 kB)\n",
      "   ---------------------------------------- 0.0/884.3 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/884.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 884.3/884.3 kB 1.9 MB/s  0:00:00\n",
      "Downloading regex-2025.9.18-cp312-cp312-win_amd64.whl (275 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, jiter, distro, tiktoken, openai, langchain-openai, langchain-deepseek\n",
      "\n",
      "   ---------------------------------------- 0/8 [tqdm]\n",
      "   ---------------------------------------- 0/8 [tqdm]\n",
      "   ---------------------------------------- 0/8 [tqdm]\n",
      "   ---------------------------------------- 0/8 [tqdm]\n",
      "   ----- ---------------------------------- 1/8 [regex]\n",
      "   ----- ---------------------------------- 1/8 [regex]\n",
      "   --------------- ------------------------ 3/8 [distro]\n",
      "   --------------- ------------------------ 3/8 [distro]\n",
      "   -------------------- ------------------- 4/8 [tiktoken]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ---------------------------------------- 8/8 [langchain-deepseek]\n",
      "\n",
      "Successfully installed distro-1.9.0 jiter-0.11.0 langchain-deepseek-0.1.4 langchain-openai-0.3.33 openai-1.109.1 regex-2025.9.18 tiktoken-0.11.0 tqdm-4.67.1\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T13:02:14.851635Z",
     "start_time": "2025-09-30T13:02:02.902168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 导入Lanchain集成的DeepSeek 聊天模型\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "# 导入环境变量加载工具\n",
    "from dotenv import load_dotenv\n",
    "# 导入操作系统相关功能\n",
    "import os\n",
    "\n",
    "# 加载.env文件中的环境变量\n",
    "load_dotenv()\n",
    "\n",
    "# 创建DeepSeek 聊天模型实例\n",
    "chat = ChatDeepSeek(\n",
    "    temperature=0,  # temperature=0表示输出更加确定性，不会随机性太强\n",
    "    model_name=\"deepseek-chat\",  # 模型名称\n",
    "    api_key=os.getenv(\"DEEPSEEK_API_KEY\")  # 从环境变量中获取API密钥\n",
    ")\n",
    "\n",
    "# 定义对话消息列表，包含系统角色消息和用户角色消息\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"你是一个有帮助的AI助手。\"},\n",
    "    {\"role\": \"user\", \"content\": \"你好！请介绍一下你自己。\"}\n",
    "]\n",
    "\n",
    "# 调用模型生成回复\n",
    "response = chat.invoke(messages)\n",
    "\n",
    "# 打印AI助手的回复内容\n",
    "print(response.content)"
   ],
   "id": "25bac9d6f465312d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！很高兴认识你！😊\n",
      "\n",
      "我是DeepSeek，由深度求索公司创造的AI助手。让我简单介绍一下自己：\n",
      "\n",
      "**我的特点：**\n",
      "- 📚 知识截止到2024年7月，是DeepSeek最新版本模型\n",
      "- 💬 纯文本对话模型，擅长各种文字交流和分析\n",
      "- 📁 支持文件上传功能，可以处理图像、txt、pdf、ppt、word、excel等文件，读取其中的文字信息\n",
      "- 🌐 支持联网搜索（需要你在Web/App手动开启）\n",
      "- 💾 拥有128K的上下文处理能力\n",
      "- 📱 有官方App可供下载使用\n",
      "\n",
      "**我能帮你什么：**\n",
      "- 回答各种问题和解疑答惑\n",
      "- 协助写作、翻译、分析\n",
      "- 处理和分析上传的文档内容\n",
      "- 提供学习和工作上的建议\n",
      "- 进行有趣的对话和讨论\n",
      "\n",
      "**需要注意的是：**\n",
      "- 我不支持多模态识别功能\n",
      "- 没有语音功能\n",
      "- 完全免费使用，没有任何收费计划\n",
      "\n",
      "有什么我可以帮你的吗？无论是学习、工作还是日常问题，我都很乐意协助你！✨\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T13:07:51.227682Z",
     "start_time": "2025-09-30T13:07:29.041462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 导入Lanchain集成的DeepSeek 聊天模型\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "# 导入环境变量加载工具\n",
    "from dotenv import load_dotenv\n",
    "# 导入操作系统相关功能\n",
    "import os\n",
    "\n",
    "# 加载.env文件中的环境变量\n",
    "load_dotenv()\n",
    "\n",
    "# 创建DeepSeek 聊天模型实例\n",
    "chat = ChatDeepSeek(\n",
    "    temperature=0,  # temperature=0表示输出更加确定性，不会随机性太强\n",
    "    model_name=\"deepseek-chat\",  # 模型名称\n",
    "    api_key=os.getenv(\"DEEPSEEK_API_KEY\")  # 从环境变量中获取API密钥\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"你是一个起名大师, 请模仿示例起3个{county}名字，比如男孩经常被叫做{boy}, 女孩经常被叫做{girl}\")\n",
    "# 定义对话消息列表，包含系统角色消息和用户角色消息\n",
    "messages = prompt.format(county=\"中国\", boy=\"狗剩\", girl=\"翠花\")\n",
    "print(messages)\n",
    "# 调用模型生成回复\n",
    "response = chat.invoke(messages)\n",
    "\n",
    "# 打印AI助手的回复内容\n",
    "print(response.content)"
   ],
   "id": "e474c393061908cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是一个起名大师, 请模仿示例起3个中国名字，比如男孩经常被叫做狗剩, 女孩经常被叫做翠花\n",
      "好的，起名大师这就为您献上几个充满“乡土气息”和“时代印记”的经典之作。这些名字朴实无华，朗朗上口，蕴含着老一辈人对孩子健康、好养活的深切期盼。\n",
      "\n",
      "**仿照示例，为您奉上三组名字：**\n",
      "\n",
      "**第一组：男孩名**\n",
      "\n",
      "1.  **铁柱** - 寓意孩子身体像铁打的柱子一样结实、强壮，风吹不倒。\n",
      "2.  **石头** - 象征孩子像石头一样坚硬、皮实，生命力顽强。\n",
      "3.  **建国** - 带有鲜明的时代色彩，寄托了父母对建设新家园、报效祖国的美好愿望。\n",
      "\n",
      "**第二组：女孩名**\n",
      "\n",
      "1.  **秀英** - “秀”指秀丽，“英”是花朵、精英，组合在一起是那个年代对女孩“俊秀出众”的经典祝愿。\n",
      "2.  **春妮** - 充满了春天的气息，“妮”是对女孩的亲昵称呼，听起来亲切又活泼。\n",
      "3.  **招娣** - 这个名字带有特定的时代烙印，反映了过去一些家庭期盼迎来男孩的传统观念。\n",
      "\n",
      "**第三组：小名/乳名（不分男女，更显亲昵）**\n",
      "\n",
      "1.  **二蛋** - 通常用于家里第二个男孩，显得憨厚可爱，寓意像蛋一样圆润好养活。\n",
      "2.  **妞妞** - 对小女孩的通用爱称，充满了疼爱之情。\n",
      "3.  **毛头** - 形容刚出生时头发毛茸茸的样子，非常形象生动，常用于男孩。\n",
      "\n",
      "---\n",
      "\n",
      "**起名思路解析：**\n",
      "\n",
      "这类名字之所以经典，是因为它们通常具备以下特点：\n",
      "\n",
      "*   **寓意朴实直接**：不追求风雅，而是聚焦于“健康”、“皮实”、“好养活”等最根本的愿望。\n",
      "*   **用字接地气**：多选用生活中常见的事物，如动物（狗、牛）、植物（花、草）、自然物（石、铁）等。\n",
      "*   **富有时代感**：像“建国”、“援朝”等，是一个时代的集体记忆。\n",
      "*   **朗朗上口**：发音响亮，容易记忆，充满了生活气息。\n",
      "\n",
      "希望这些充满“年代感”的名字能让您会心一笑！如果您想为孩子取一个既符合现代审美又不失传统韵味的好名字，我也非常乐意效劳。\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T13:11:23.629556Z",
     "start_time": "2025-09-30T13:11:23.617760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 结构化输出的例子\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "CommaSeparatedListOutputParser().parse(\"hi, bye\")"
   ],
   "id": "6656617983f14490",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'bye']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T13:15:44.625429Z",
     "start_time": "2025-09-30T13:15:42.806494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 起名大师，输出格式为一个数组\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "# 导入环境变量加载工具\n",
    "from dotenv import load_dotenv\n",
    "# 导入操作系统相关功能\n",
    "import os\n",
    "\n",
    "# 加载.env文件中的环境变量\n",
    "load_dotenv()\n",
    "\n",
    "# 自定义类\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        print(text)\n",
    "        return text.strip().split(\",\")\n",
    "\n",
    "# 创建DeepSeek 聊天模型实例\n",
    "chat = ChatDeepSeek(\n",
    "    temperature=0,  # temperature=0表示输出更加确定性，不会随机性太强\n",
    "    model_name=\"deepseek-chat\",  # 模型名称\n",
    "    api_key=os.getenv(\"DEEPSEEK_API_KEY\")  # 从环境变量中获取API密钥\n",
    ")\n",
    "\n",
    "# 创建提示模板\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"你是一个起名大师，请模仿示例起3个具有{county}特色的名字，示例：男孩常用名{boy}，女孩常用名{girl}。请返回以逗号分隔的列表形式。仅返回逗号分隔的列表，不要返回其他内容。\"\n",
    ")\n",
    "\n",
    "# 格式化提示信息\n",
    "message = prompt.format(county=\"美国男孩\", boy=\"sam\", girl=\"lucy\")\n",
    "print(message)\n",
    "\n",
    "# 调用模型生成结果\n",
    "strs = chat.invoke(message)\n",
    "\n",
    "# 解析输出结果\n",
    "result = CommaSeparatedListOutputParser().parse(strs.content)\n",
    "print(result)"
   ],
   "id": "dabe64ec9d24c2d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是一个起名大师，请模仿示例起3个具有美国男孩特色的名字，示例：男孩常用名sam，女孩常用名lucy。请返回以逗号分隔的列表形式。仅返回逗号分隔的列表，不要返回其他内容。\n",
      "michael, ethan, alexander\n",
      "['michael', ' ethan', ' alexander']\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
