{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-30T12:44:39.661676Z",
     "start_time": "2025-09-30T12:43:24.220300Z"
    }
   },
   "source": "! pip install langchain dotenv",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
      "  Downloading langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.4.31-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.43-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langchain) (6.0.3)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.2.4-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Collecting orjson>=3.9.14 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading orjson-3.11.3-cp312-cp312-win_amd64.whl.metadata (43 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.25.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.5/1.0 MB 209.7 kB/s eta 0:00:03\n",
      "   -------------------- ------------------- 0.5/1.0 MB 209.7 kB/s eta 0:00:03\n",
      "   -------------------- ------------------- 0.5/1.0 MB 209.7 kB/s eta 0:00:03\n",
      "   -------------------- ------------------- 0.5/1.0 MB 209.7 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 0.8/1.0 MB 241.4 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 0.8/1.0 MB 241.4 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 0.8/1.0 MB 241.4 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 0.8/1.0 MB 241.4 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 0.8/1.0 MB 241.4 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 0.8/1.0 MB 241.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 225.0 kB/s  0:00:05\n",
      "Downloading langchain_core-0.3.76-py3-none-any.whl (447 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
      "Downloading pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 188.6 kB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 188.6 kB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 188.6 kB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 188.6 kB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 188.6 kB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 188.6 kB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 197.4 kB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 197.4 kB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 197.4 kB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 197.4 kB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 197.4 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 1.0/2.0 MB 204.6 kB/s eta 0:00:05\n",
      "   --------------------- ------------------ 1.0/2.0 MB 204.6 kB/s eta 0:00:05\n",
      "   --------------------- ------------------ 1.0/2.0 MB 204.6 kB/s eta 0:00:05\n",
      "   --------------------- ------------------ 1.0/2.0 MB 204.6 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 1.3/2.0 MB 232.2 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 1.6/2.0 MB 273.2 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 1.8/2.0 MB 307.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 329.5 kB/s  0:00:05\n",
      "Downloading sqlalchemy-2.0.43-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.1 MB 985.5 kB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.8/2.1 MB 932.9 kB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.0/2.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.0/2.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.0/2.1 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.3/2.1 MB 737.4 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.3/2.1 MB 737.4 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 1.8/2.1 MB 883.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 889.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 890.2 kB/s  0:00:02\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading greenlet-3.2.4-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Downloading langsmith-0.4.31-py3-none-any.whl (386 kB)\n",
      "Downloading orjson-3.11.3-cp312-cp312-win_amd64.whl (131 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading zstandard-0.25.0-cp312-cp312-win_amd64.whl (506 kB)\n",
      "Installing collected packages: zstandard, typing-inspection, tenacity, pydantic-core, orjson, jsonpatch, greenlet, annotated-types, SQLAlchemy, requests-toolbelt, pydantic, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "\n",
      "   ---------- -----------------------------  4/15 [orjson]\n",
      "   ---------------- -----------------------  6/15 [greenlet]\n",
      "   --------------------- ------------------  8/15 [SQLAlchemy]\n",
      "   --------------------- ------------------  8/15 [SQLAlchemy]\n",
      "   --------------------- ------------------  8/15 [SQLAlchemy]\n",
      "   --------------------- ------------------  8/15 [SQLAlchemy]\n",
      "   --------------------- ------------------  8/15 [SQLAlchemy]\n",
      "   --------------------- ------------------  8/15 [SQLAlchemy]\n",
      "   --------------------- ------------------  8/15 [SQLAlchemy]\n",
      "   --------------------- ------------------  8/15 [SQLAlchemy]\n",
      "   --------------------- ------------------  8/15 [SQLAlchemy]\n",
      "   --------------------- ------------------  8/15 [SQLAlchemy]\n",
      "   --------------------- ------------------  8/15 [SQLAlchemy]\n",
      "   --------------------- ------------------  8/15 [SQLAlchemy]\n",
      "   ------------------------ ---------------  9/15 [requests-toolbelt]\n",
      "   -------------------------- ------------- 10/15 [pydantic]\n",
      "   -------------------------- ------------- 10/15 [pydantic]\n",
      "   -------------------------- ------------- 10/15 [pydantic]\n",
      "   ----------------------------- ---------- 11/15 [langsmith]\n",
      "   ----------------------------- ---------- 11/15 [langsmith]\n",
      "   -------------------------------- ------- 12/15 [langchain-core]\n",
      "   -------------------------------- ------- 12/15 [langchain-core]\n",
      "   -------------------------------- ------- 12/15 [langchain-core]\n",
      "   -------------------------------- ------- 12/15 [langchain-core]\n",
      "   -------------------------------- ------- 12/15 [langchain-core]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ---------------------------------------- 15/15 [langchain]\n",
      "\n",
      "Successfully installed SQLAlchemy-2.0.43 annotated-types-0.7.0 greenlet-3.2.4 jsonpatch-1.33 langchain-0.3.27 langchain-core-0.3.76 langchain-text-splitters-0.3.11 langsmith-0.4.31 orjson-3.11.3 pydantic-2.11.9 pydantic-core-2.33.2 requests-toolbelt-1.0.0 tenacity-9.1.2 typing-inspection-0.4.1 zstandard-0.25.0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T12:45:46.330577Z",
     "start_time": "2025-09-30T12:45:45.718081Z"
    }
   },
   "cell_type": "code",
   "source": "! pip show langchain",
   "id": "3df1ed5910eacc3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.3.27\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: C:\\Users\\jz292\\.conda\\envs\\langchain-learning\\Lib\\site-packages\n",
      "Requires: langchain-core, langchain-text-splitters, langsmith, pydantic, PyYAML, requests, SQLAlchemy\n",
      "Required-by: \n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T12:59:03.825028Z",
     "start_time": "2025-09-30T12:58:34.527930Z"
    }
   },
   "cell_type": "code",
   "source": "! pip install langchain-deepseek",
   "id": "44d1378dc42d3352",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-deepseek\n",
      "  Downloading langchain_deepseek-0.1.4-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.70 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langchain-deepseek) (0.3.76)\n",
      "Collecting langchain-openai<1.0.0,>=0.3.28 (from langchain-deepseek)\n",
      "  Downloading langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (0.4.31)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (6.0.3)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (25.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (2.11.9)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (3.0.0)\n",
      "Collecting openai<2.0.0,>=1.104.2 (from langchain-openai<1.0.0,>=0.3.28->langchain-deepseek)\n",
      "  Downloading openai-1.109.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai<1.0.0,>=0.3.28->langchain-deepseek)\n",
      "  Downloading tiktoken-0.11.0-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from openai<2.0.0,>=1.104.2->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (4.11.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.104.2->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from openai<2.0.0,>=1.104.2->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.104.2->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek)\n",
      "  Downloading jiter-0.11.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from openai<2.0.0,>=1.104.2->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (1.3.1)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.104.2->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.104.2->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (0.4.1)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek)\n",
      "  Downloading regex-2025.9.18-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (2.32.5)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-deepseek) (0.25.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jz292\\.conda\\envs\\langchain-learning\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.104.2->langchain-openai<1.0.0,>=0.3.28->langchain-deepseek) (0.4.6)\n",
      "Downloading langchain_deepseek-0.1.4-py3-none-any.whl (7.4 kB)\n",
      "Downloading langchain_openai-0.3.33-py3-none-any.whl (74 kB)\n",
      "Downloading openai-1.109.1-py3-none-any.whl (948 kB)\n",
      "   ---------------------------------------- 0.0/948.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/948.6 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/948.6 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/948.6 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 786.4/948.6 kB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 948.6/948.6 kB 1.2 MB/s  0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.11.0-cp312-cp312-win_amd64.whl (203 kB)\n",
      "Downloading tiktoken-0.11.0-cp312-cp312-win_amd64.whl (884 kB)\n",
      "   ---------------------------------------- 0.0/884.3 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/884.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 884.3/884.3 kB 1.9 MB/s  0:00:00\n",
      "Downloading regex-2025.9.18-cp312-cp312-win_amd64.whl (275 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, jiter, distro, tiktoken, openai, langchain-openai, langchain-deepseek\n",
      "\n",
      "   ---------------------------------------- 0/8 [tqdm]\n",
      "   ---------------------------------------- 0/8 [tqdm]\n",
      "   ---------------------------------------- 0/8 [tqdm]\n",
      "   ---------------------------------------- 0/8 [tqdm]\n",
      "   ----- ---------------------------------- 1/8 [regex]\n",
      "   ----- ---------------------------------- 1/8 [regex]\n",
      "   --------------- ------------------------ 3/8 [distro]\n",
      "   --------------- ------------------------ 3/8 [distro]\n",
      "   -------------------- ------------------- 4/8 [tiktoken]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ------------------------- -------------- 5/8 [openai]\n",
      "   ---------------------------------------- 8/8 [langchain-deepseek]\n",
      "\n",
      "Successfully installed distro-1.9.0 jiter-0.11.0 langchain-deepseek-0.1.4 langchain-openai-0.3.33 openai-1.109.1 regex-2025.9.18 tiktoken-0.11.0 tqdm-4.67.1\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T13:02:14.851635Z",
     "start_time": "2025-09-30T13:02:02.902168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# å¯¼å…¥Lanchainé›†æˆçš„DeepSeek èŠå¤©æ¨¡å‹\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "# å¯¼å…¥ç¯å¢ƒå˜é‡åŠ è½½å·¥å…·\n",
    "from dotenv import load_dotenv\n",
    "# å¯¼å…¥æ“ä½œç³»ç»Ÿç›¸å…³åŠŸèƒ½\n",
    "import os\n",
    "\n",
    "# åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "# åˆ›å»ºDeepSeek èŠå¤©æ¨¡å‹å®ä¾‹\n",
    "chat = ChatDeepSeek(\n",
    "    temperature=0,  # temperature=0è¡¨ç¤ºè¾“å‡ºæ›´åŠ ç¡®å®šæ€§ï¼Œä¸ä¼šéšæœºæ€§å¤ªå¼º\n",
    "    model_name=\"deepseek-chat\",  # æ¨¡å‹åç§°\n",
    "    api_key=os.getenv(\"DEEPSEEK_API_KEY\")  # ä»ç¯å¢ƒå˜é‡ä¸­è·å–APIå¯†é’¥\n",
    ")\n",
    "\n",
    "# å®šä¹‰å¯¹è¯æ¶ˆæ¯åˆ—è¡¨ï¼ŒåŒ…å«ç³»ç»Ÿè§’è‰²æ¶ˆæ¯å’Œç”¨æˆ·è§’è‰²æ¶ˆæ¯\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹ã€‚\"},\n",
    "    {\"role\": \"user\", \"content\": \"ä½ å¥½ï¼è¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚\"}\n",
    "]\n",
    "\n",
    "# è°ƒç”¨æ¨¡å‹ç”Ÿæˆå›å¤\n",
    "response = chat.invoke(messages)\n",
    "\n",
    "# æ‰“å°AIåŠ©æ‰‹çš„å›å¤å†…å®¹\n",
    "print(response.content)"
   ],
   "id": "25bac9d6f465312d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼ğŸ˜Š\n",
      "\n",
      "æˆ‘æ˜¯DeepSeekï¼Œç”±æ·±åº¦æ±‚ç´¢å…¬å¸åˆ›é€ çš„AIåŠ©æ‰‹ã€‚è®©æˆ‘ç®€å•ä»‹ç»ä¸€ä¸‹è‡ªå·±ï¼š\n",
      "\n",
      "**æˆ‘çš„ç‰¹ç‚¹ï¼š**\n",
      "- ğŸ“š çŸ¥è¯†æˆªæ­¢åˆ°2024å¹´7æœˆï¼Œæ˜¯DeepSeekæœ€æ–°ç‰ˆæœ¬æ¨¡å‹\n",
      "- ğŸ’¬ çº¯æ–‡æœ¬å¯¹è¯æ¨¡å‹ï¼Œæ“…é•¿å„ç§æ–‡å­—äº¤æµå’Œåˆ†æ\n",
      "- ğŸ“ æ”¯æŒæ–‡ä»¶ä¸Šä¼ åŠŸèƒ½ï¼Œå¯ä»¥å¤„ç†å›¾åƒã€txtã€pdfã€pptã€wordã€excelç­‰æ–‡ä»¶ï¼Œè¯»å–å…¶ä¸­çš„æ–‡å­—ä¿¡æ¯\n",
      "- ğŸŒ æ”¯æŒè”ç½‘æœç´¢ï¼ˆéœ€è¦ä½ åœ¨Web/Appæ‰‹åŠ¨å¼€å¯ï¼‰\n",
      "- ğŸ’¾ æ‹¥æœ‰128Kçš„ä¸Šä¸‹æ–‡å¤„ç†èƒ½åŠ›\n",
      "- ğŸ“± æœ‰å®˜æ–¹Appå¯ä¾›ä¸‹è½½ä½¿ç”¨\n",
      "\n",
      "**æˆ‘èƒ½å¸®ä½ ä»€ä¹ˆï¼š**\n",
      "- å›ç­”å„ç§é—®é¢˜å’Œè§£ç–‘ç­”æƒ‘\n",
      "- ååŠ©å†™ä½œã€ç¿»è¯‘ã€åˆ†æ\n",
      "- å¤„ç†å’Œåˆ†æä¸Šä¼ çš„æ–‡æ¡£å†…å®¹\n",
      "- æä¾›å­¦ä¹ å’Œå·¥ä½œä¸Šçš„å»ºè®®\n",
      "- è¿›è¡Œæœ‰è¶£çš„å¯¹è¯å’Œè®¨è®º\n",
      "\n",
      "**éœ€è¦æ³¨æ„çš„æ˜¯ï¼š**\n",
      "- æˆ‘ä¸æ”¯æŒå¤šæ¨¡æ€è¯†åˆ«åŠŸèƒ½\n",
      "- æ²¡æœ‰è¯­éŸ³åŠŸèƒ½\n",
      "- å®Œå…¨å…è´¹ä½¿ç”¨ï¼Œæ²¡æœ‰ä»»ä½•æ”¶è´¹è®¡åˆ’\n",
      "\n",
      "æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿæ— è®ºæ˜¯å­¦ä¹ ã€å·¥ä½œè¿˜æ˜¯æ—¥å¸¸é—®é¢˜ï¼Œæˆ‘éƒ½å¾ˆä¹æ„ååŠ©ä½ ï¼âœ¨\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T13:07:51.227682Z",
     "start_time": "2025-09-30T13:07:29.041462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# å¯¼å…¥Lanchainé›†æˆçš„DeepSeek èŠå¤©æ¨¡å‹\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "# å¯¼å…¥ç¯å¢ƒå˜é‡åŠ è½½å·¥å…·\n",
    "from dotenv import load_dotenv\n",
    "# å¯¼å…¥æ“ä½œç³»ç»Ÿç›¸å…³åŠŸèƒ½\n",
    "import os\n",
    "\n",
    "# åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "# åˆ›å»ºDeepSeek èŠå¤©æ¨¡å‹å®ä¾‹\n",
    "chat = ChatDeepSeek(\n",
    "    temperature=0,  # temperature=0è¡¨ç¤ºè¾“å‡ºæ›´åŠ ç¡®å®šæ€§ï¼Œä¸ä¼šéšæœºæ€§å¤ªå¼º\n",
    "    model_name=\"deepseek-chat\",  # æ¨¡å‹åç§°\n",
    "    api_key=os.getenv(\"DEEPSEEK_API_KEY\")  # ä»ç¯å¢ƒå˜é‡ä¸­è·å–APIå¯†é’¥\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"ä½ æ˜¯ä¸€ä¸ªèµ·åå¤§å¸ˆ, è¯·æ¨¡ä»¿ç¤ºä¾‹èµ·3ä¸ª{county}åå­—ï¼Œæ¯”å¦‚ç”·å­©ç»å¸¸è¢«å«åš{boy}, å¥³å­©ç»å¸¸è¢«å«åš{girl}\")\n",
    "# å®šä¹‰å¯¹è¯æ¶ˆæ¯åˆ—è¡¨ï¼ŒåŒ…å«ç³»ç»Ÿè§’è‰²æ¶ˆæ¯å’Œç”¨æˆ·è§’è‰²æ¶ˆæ¯\n",
    "messages = prompt.format(county=\"ä¸­å›½\", boy=\"ç‹—å‰©\", girl=\"ç¿ èŠ±\")\n",
    "print(messages)\n",
    "# è°ƒç”¨æ¨¡å‹ç”Ÿæˆå›å¤\n",
    "response = chat.invoke(messages)\n",
    "\n",
    "# æ‰“å°AIåŠ©æ‰‹çš„å›å¤å†…å®¹\n",
    "print(response.content)"
   ],
   "id": "e474c393061908cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ æ˜¯ä¸€ä¸ªèµ·åå¤§å¸ˆ, è¯·æ¨¡ä»¿ç¤ºä¾‹èµ·3ä¸ªä¸­å›½åå­—ï¼Œæ¯”å¦‚ç”·å­©ç»å¸¸è¢«å«åšç‹—å‰©, å¥³å­©ç»å¸¸è¢«å«åšç¿ èŠ±\n",
      "å¥½çš„ï¼Œèµ·åå¤§å¸ˆè¿™å°±ä¸ºæ‚¨çŒ®ä¸Šå‡ ä¸ªå……æ»¡â€œä¹¡åœŸæ°”æ¯â€å’Œâ€œæ—¶ä»£å°è®°â€çš„ç»å…¸ä¹‹ä½œã€‚è¿™äº›åå­—æœ´å®æ— åï¼Œæœ—æœ—ä¸Šå£ï¼Œè•´å«ç€è€ä¸€è¾ˆäººå¯¹å­©å­å¥åº·ã€å¥½å…»æ´»çš„æ·±åˆ‡æœŸç›¼ã€‚\n",
      "\n",
      "**ä»¿ç…§ç¤ºä¾‹ï¼Œä¸ºæ‚¨å¥‰ä¸Šä¸‰ç»„åå­—ï¼š**\n",
      "\n",
      "**ç¬¬ä¸€ç»„ï¼šç”·å­©å**\n",
      "\n",
      "1.  **é“æŸ±** - å¯“æ„å­©å­èº«ä½“åƒé“æ‰“çš„æŸ±å­ä¸€æ ·ç»“å®ã€å¼ºå£®ï¼Œé£å¹ä¸å€’ã€‚\n",
      "2.  **çŸ³å¤´** - è±¡å¾å­©å­åƒçŸ³å¤´ä¸€æ ·åšç¡¬ã€çš®å®ï¼Œç”Ÿå‘½åŠ›é¡½å¼ºã€‚\n",
      "3.  **å»ºå›½** - å¸¦æœ‰é²œæ˜çš„æ—¶ä»£è‰²å½©ï¼Œå¯„æ‰˜äº†çˆ¶æ¯å¯¹å»ºè®¾æ–°å®¶å›­ã€æŠ¥æ•ˆç¥–å›½çš„ç¾å¥½æ„¿æœ›ã€‚\n",
      "\n",
      "**ç¬¬äºŒç»„ï¼šå¥³å­©å**\n",
      "\n",
      "1.  **ç§€è‹±** - â€œç§€â€æŒ‡ç§€ä¸½ï¼Œâ€œè‹±â€æ˜¯èŠ±æœµã€ç²¾è‹±ï¼Œç»„åˆåœ¨ä¸€èµ·æ˜¯é‚£ä¸ªå¹´ä»£å¯¹å¥³å­©â€œä¿Šç§€å‡ºä¼—â€çš„ç»å…¸ç¥æ„¿ã€‚\n",
      "2.  **æ˜¥å¦®** - å……æ»¡äº†æ˜¥å¤©çš„æ°”æ¯ï¼Œâ€œå¦®â€æ˜¯å¯¹å¥³å­©çš„äº²æ˜µç§°å‘¼ï¼Œå¬èµ·æ¥äº²åˆ‡åˆæ´»æ³¼ã€‚\n",
      "3.  **æ‹›å¨£** - è¿™ä¸ªåå­—å¸¦æœ‰ç‰¹å®šçš„æ—¶ä»£çƒ™å°ï¼Œåæ˜ äº†è¿‡å»ä¸€äº›å®¶åº­æœŸç›¼è¿æ¥ç”·å­©çš„ä¼ ç»Ÿè§‚å¿µã€‚\n",
      "\n",
      "**ç¬¬ä¸‰ç»„ï¼šå°å/ä¹³åï¼ˆä¸åˆ†ç”·å¥³ï¼Œæ›´æ˜¾äº²æ˜µï¼‰**\n",
      "\n",
      "1.  **äºŒè›‹** - é€šå¸¸ç”¨äºå®¶é‡Œç¬¬äºŒä¸ªç”·å­©ï¼Œæ˜¾å¾—æ†¨åšå¯çˆ±ï¼Œå¯“æ„åƒè›‹ä¸€æ ·åœ†æ¶¦å¥½å…»æ´»ã€‚\n",
      "2.  **å¦å¦** - å¯¹å°å¥³å­©çš„é€šç”¨çˆ±ç§°ï¼Œå……æ»¡äº†ç–¼çˆ±ä¹‹æƒ…ã€‚\n",
      "3.  **æ¯›å¤´** - å½¢å®¹åˆšå‡ºç”Ÿæ—¶å¤´å‘æ¯›èŒ¸èŒ¸çš„æ ·å­ï¼Œéå¸¸å½¢è±¡ç”ŸåŠ¨ï¼Œå¸¸ç”¨äºç”·å­©ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "**èµ·åæ€è·¯è§£æï¼š**\n",
      "\n",
      "è¿™ç±»åå­—ä¹‹æ‰€ä»¥ç»å…¸ï¼Œæ˜¯å› ä¸ºå®ƒä»¬é€šå¸¸å…·å¤‡ä»¥ä¸‹ç‰¹ç‚¹ï¼š\n",
      "\n",
      "*   **å¯“æ„æœ´å®ç›´æ¥**ï¼šä¸è¿½æ±‚é£é›…ï¼Œè€Œæ˜¯èšç„¦äºâ€œå¥åº·â€ã€â€œçš®å®â€ã€â€œå¥½å…»æ´»â€ç­‰æœ€æ ¹æœ¬çš„æ„¿æœ›ã€‚\n",
      "*   **ç”¨å­—æ¥åœ°æ°”**ï¼šå¤šé€‰ç”¨ç”Ÿæ´»ä¸­å¸¸è§çš„äº‹ç‰©ï¼Œå¦‚åŠ¨ç‰©ï¼ˆç‹—ã€ç‰›ï¼‰ã€æ¤ç‰©ï¼ˆèŠ±ã€è‰ï¼‰ã€è‡ªç„¶ç‰©ï¼ˆçŸ³ã€é“ï¼‰ç­‰ã€‚\n",
      "*   **å¯Œæœ‰æ—¶ä»£æ„Ÿ**ï¼šåƒâ€œå»ºå›½â€ã€â€œæ´æœâ€ç­‰ï¼Œæ˜¯ä¸€ä¸ªæ—¶ä»£çš„é›†ä½“è®°å¿†ã€‚\n",
      "*   **æœ—æœ—ä¸Šå£**ï¼šå‘éŸ³å“äº®ï¼Œå®¹æ˜“è®°å¿†ï¼Œå……æ»¡äº†ç”Ÿæ´»æ°”æ¯ã€‚\n",
      "\n",
      "å¸Œæœ›è¿™äº›å……æ»¡â€œå¹´ä»£æ„Ÿâ€çš„åå­—èƒ½è®©æ‚¨ä¼šå¿ƒä¸€ç¬‘ï¼å¦‚æœæ‚¨æƒ³ä¸ºå­©å­å–ä¸€ä¸ªæ—¢ç¬¦åˆç°ä»£å®¡ç¾åˆä¸å¤±ä¼ ç»ŸéŸµå‘³çš„å¥½åå­—ï¼Œæˆ‘ä¹Ÿéå¸¸ä¹æ„æ•ˆåŠ³ã€‚\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T13:11:23.629556Z",
     "start_time": "2025-09-30T13:11:23.617760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ç»“æ„åŒ–è¾“å‡ºçš„ä¾‹å­\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "CommaSeparatedListOutputParser().parse(\"hi, bye\")"
   ],
   "id": "6656617983f14490",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'bye']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T13:15:44.625429Z",
     "start_time": "2025-09-30T13:15:42.806494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# èµ·åå¤§å¸ˆï¼Œè¾“å‡ºæ ¼å¼ä¸ºä¸€ä¸ªæ•°ç»„\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "# å¯¼å…¥ç¯å¢ƒå˜é‡åŠ è½½å·¥å…·\n",
    "from dotenv import load_dotenv\n",
    "# å¯¼å…¥æ“ä½œç³»ç»Ÿç›¸å…³åŠŸèƒ½\n",
    "import os\n",
    "\n",
    "# åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "# è‡ªå®šä¹‰ç±»\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        print(text)\n",
    "        return text.strip().split(\",\")\n",
    "\n",
    "# åˆ›å»ºDeepSeek èŠå¤©æ¨¡å‹å®ä¾‹\n",
    "chat = ChatDeepSeek(\n",
    "    temperature=0,  # temperature=0è¡¨ç¤ºè¾“å‡ºæ›´åŠ ç¡®å®šæ€§ï¼Œä¸ä¼šéšæœºæ€§å¤ªå¼º\n",
    "    model_name=\"deepseek-chat\",  # æ¨¡å‹åç§°\n",
    "    api_key=os.getenv(\"DEEPSEEK_API_KEY\")  # ä»ç¯å¢ƒå˜é‡ä¸­è·å–APIå¯†é’¥\n",
    ")\n",
    "\n",
    "# åˆ›å»ºæç¤ºæ¨¡æ¿\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"ä½ æ˜¯ä¸€ä¸ªèµ·åå¤§å¸ˆï¼Œè¯·æ¨¡ä»¿ç¤ºä¾‹èµ·3ä¸ªå…·æœ‰{county}ç‰¹è‰²çš„åå­—ï¼Œç¤ºä¾‹ï¼šç”·å­©å¸¸ç”¨å{boy}ï¼Œå¥³å­©å¸¸ç”¨å{girl}ã€‚è¯·è¿”å›ä»¥é€—å·åˆ†éš”çš„åˆ—è¡¨å½¢å¼ã€‚ä»…è¿”å›é€—å·åˆ†éš”çš„åˆ—è¡¨ï¼Œä¸è¦è¿”å›å…¶ä»–å†…å®¹ã€‚\"\n",
    ")\n",
    "\n",
    "# æ ¼å¼åŒ–æç¤ºä¿¡æ¯\n",
    "message = prompt.format(county=\"ç¾å›½ç”·å­©\", boy=\"sam\", girl=\"lucy\")\n",
    "print(message)\n",
    "\n",
    "# è°ƒç”¨æ¨¡å‹ç”Ÿæˆç»“æœ\n",
    "strs = chat.invoke(message)\n",
    "\n",
    "# è§£æè¾“å‡ºç»“æœ\n",
    "result = CommaSeparatedListOutputParser().parse(strs.content)\n",
    "print(result)"
   ],
   "id": "dabe64ec9d24c2d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ æ˜¯ä¸€ä¸ªèµ·åå¤§å¸ˆï¼Œè¯·æ¨¡ä»¿ç¤ºä¾‹èµ·3ä¸ªå…·æœ‰ç¾å›½ç”·å­©ç‰¹è‰²çš„åå­—ï¼Œç¤ºä¾‹ï¼šç”·å­©å¸¸ç”¨åsamï¼Œå¥³å­©å¸¸ç”¨ålucyã€‚è¯·è¿”å›ä»¥é€—å·åˆ†éš”çš„åˆ—è¡¨å½¢å¼ã€‚ä»…è¿”å›é€—å·åˆ†éš”çš„åˆ—è¡¨ï¼Œä¸è¦è¿”å›å…¶ä»–å†…å®¹ã€‚\n",
      "michael, ethan, alexander\n",
      "['michael', ' ethan', ' alexander']\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
