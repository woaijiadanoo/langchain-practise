{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# OutputParser 练习",
   "id": "7337d9ba911c36af"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# StrOutputParser",
   "id": "e06771221bc9935f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T12:30:25.855733Z",
     "start_time": "2025-10-11T12:30:23.374297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 导入所需的库\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# --- 1. 定义LLM模型 ---\n",
    "# 这里我们使用Claude 3.5 Sonnet模型\n",
    "# 注意：你需要先设置你的API密钥和可能的访问地址作为环境变量\n",
    "import os\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "model = ChatDeepSeek(\n",
    "    temperature=0,  # temperature=0表示输出更加确定性，不会随机性太强\n",
    "    model_name=\"deepseek-chat\",  # 模型名称\n",
    "    api_key=os.getenv(\"DEEPSEEK_API_KEY\")  # 从环境变量中获取API密钥\n",
    ")\n",
    "\n",
    "# --- 2. 定义一个工具 ---\n",
    "# @tool装饰器可以将一个Python函数快速转换为Langchain可以使用的工具\n",
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"根据地名返回当地实时天气。\"\"\"\n",
    "    # 这是一个示例工具，为了演示，它总是返回相同的结果\n",
    "    return \"天气晴朗22度\"\n",
    "\n",
    "# --- 3. 将工具绑定到LLM ---\n",
    "# .bind_tools()方法让模型“知道”它可以使用这个工具\n",
    "llm_with_tools = model.bind_tools([get_weather])\n",
    "\n",
    "# --- 4. 构造一个链 (Chain) ---\n",
    "# 使用管道符“|”将模型和输出解析器连接起来\n",
    "# StrOutputParser可以简化输出，直接提取文本内容\n",
    "chain = llm_with_tools | StrOutputParser()\n",
    "\n",
    "# --- 5. 调用链并执行 ---\n",
    "# .invoke()方法是运行一个链的标准方式\n",
    "response = chain.invoke(\"北京市今天的天气如何？\")\n",
    "\n",
    "# --- 6. 打印结果 ---\n",
    "print(response)"
   ],
   "id": "1d0f905f5aa75682",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我来帮您查询北京市今天的天气情况。\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# PydanticOutputParser",
   "id": "4bf36ab6f7cd2d1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T13:11:56.418017Z",
     "start_time": "2025-10-11T13:11:53.875365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 1. 引入依赖包 ---\n",
    "# 这里的pydantic版本为v2\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field, model_validator\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "import os\n",
    "\n",
    "# --- 2. 使用deepseek模型 ---\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0,\n",
    "    api_key=os.environ.get(\"DEEPSEEK_API_KEY\"),\n",
    ")\n",
    "\n",
    "# --- 3. 定义一个名为Joke的数据模型 ---\n",
    "# 必须包含的数据字段：铺垫(setup)、抖包袱(punchline)\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"笑话中的铺垫问题，必须以问号结尾\")\n",
    "    punchline: str = Field(description=\"笑话中回答铺垫问题的部分，通常是一种抖包袱方式回答铺垫问题，例如谐音、会错意等\")\n",
    "\n",
    "    # 验证器, 你可以根据自己的数据情况进行自定义\n",
    "    # 注意mode=before意思是数据被转成pydantic模型的字段之前，对原始数据进行验证\n",
    "    # @model_validator(mode=\"before\")\n",
    "    # @classmethod\n",
    "    # def question_ends_with_question_mark(cls, values: dict) -> dict:\n",
    "    #     setup = values.get(\"setup\")\n",
    "    #     # 如果铺垫问题没有以问号结尾则抛出错误\n",
    "    #     if setup and setup[-1] != \"?\":\n",
    "    #         raise ValueError(\"Badly formed question!\")\n",
    "    #     return values\n",
    "\n",
    "# --- 4. 实例化解析器、提示词模板 ---\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "# 注意，提示词模板中需要部分格式化解析器的格式要求 format_instructions\n",
    "prompt = PromptTemplate(\n",
    "    template=\"回答用户的查询。\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# --- 5. 使用LCEL语法组合一个简单的链 ---\n",
    "prompt_and_model = prompt | llm\n",
    "output = prompt_and_model.invoke({\"query\": \"给我讲一个笑话\"})\n",
    "\n",
    "# 这里我们手动调用解析器来解析模型的输出\n",
    "# (在下一个示例中会看到更简洁的写法)\n",
    "parsed_output = parser.invoke(output)\n",
    "\n",
    "print(\"--- 原始输出 ---\")\n",
    "print(output)\n",
    "print(\"\\n--- 解析后的输出 ---\")\n",
    "print(parsed_output)\n",
    "\n",
    "# 你现在可以像操作一个对象一样操作解析后的结果\n",
    "print(\"\\n--- 单独访问字段 ---\")\n",
    "print(\"铺垫:\", parsed_output.setup)\n",
    "print(\"包袱:\", parsed_output.punchline)"
   ],
   "id": "e89c59f81bd96b84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始输出 ---\n",
      "content='{\\n  \"setup\": \"为什么鸡会过马路？\",\\n  \"punchline\": \"为了到另一边去！\"\\n}' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 229, 'total_tokens': 256, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 192}, 'prompt_cache_hit_tokens': 192, 'prompt_cache_miss_tokens': 37}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_ffc7281d48_prod0820_fp8_kvcache', 'id': 'a45aa4d9-6d9b-4da9-8013-fe835e5c2c32', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--66d0d7b9-f369-45ed-91f0-34462be892a0-0' usage_metadata={'input_tokens': 229, 'output_tokens': 27, 'total_tokens': 256, 'input_token_details': {'cache_read': 192}, 'output_token_details': {}}\n",
      "\n",
      "--- 解析后的输出 ---\n",
      "setup='为什么鸡会过马路？' punchline='为了到另一边去！'\n",
      "\n",
      "--- 单独访问字段 ---\n",
      "铺垫: 为什么鸡会过马路？\n",
      "包袱: 为了到另一边去！\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# JsonOutputParser + stream",
   "id": "daab61dd7908afe8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T15:05:53.826318Z",
     "start_time": "2025-10-11T15:05:46.611453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 1. 引入依赖包 ---\n",
    "# 这里的pydantic版本为v2\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field, model_validator\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "import os\n",
    "\n",
    "# --- 2. 使用deepseek模型 ---\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0,\n",
    "    api_key=os.environ.get(\"DEEPSEEK_API_KEY\"),\n",
    ")\n",
    "\n",
    "# --- 3. 定义一个名为Joke的数据模型 ---\n",
    "# 必须包含的数据字段：铺垫(setup)、抖包袱(punchline)\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"笑话中的铺垫问题，必须以问号结尾\")\n",
    "    punchline: str = Field(description=\"笑话中回答铺垫问题的部分，通常是一种抖包袱方式回答铺垫问题，例如谐音、会错意等\")\n",
    "\n",
    "    # 验证器, 你可以根据自己的数据情况进行自定义\n",
    "    # 注意mode=before意思是数据被转成pydantic模型的字段之前，对原始数据进行验证\n",
    "    # @model_validator(mode=\"before\")\n",
    "    # @classmethod\n",
    "    # def question_ends_with_question_mark(cls, values: dict) -> dict:\n",
    "    #     setup = values.get(\"setup\")\n",
    "    #     # 如果铺垫问题没有以问号结尾则抛出错误\n",
    "    #     if setup and setup[-1] != \"?\":\n",
    "    #         raise ValueError(\"Badly formed question!\")\n",
    "    #     return values\n",
    "\n",
    "# 实例化解析器，提示词模板\n",
    "# 注意：截图中高亮部分可能是视频中的笔误，应该是 PydanticOutputParser\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "# 注意，提示词模板中需要部分格式化解析器的格式要求 format_instructions\n",
    "prompt = PromptTemplate(\n",
    "    template=\"回答用户的查询。\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# 使用LCEL语法组合一个完整的链\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# 方式一：一次性调用 (Invoke)\n",
    "print(\"--- 使用 .invoke() ---\")\n",
    "output = chain.invoke({\"query\": \"给我讲一个笑话\"})\n",
    "print(output)\n",
    "print(type(output)) # 查看输出的类型\n",
    "\n",
    "# # 这行代码在截图中被注释掉了，它的作用是单独查看格式化指令\n",
    "# print(parser.get_format_instructions())\n",
    "\n",
    "# 方式二：流式输出 (Stream)\n",
    "print(\"\\n--- 使用 .stream() ---\")\n",
    "# for s in chain.stream({\"query\":\"给我讲一个关于程序员编程的笑话\"}):\n",
    "#     print(s)\n",
    "\n",
    "# 为了更好地展示流式效果，我们只看模型部分的流式输出\n",
    "streaming_chain = prompt | llm\n",
    "for chunk in streaming_chain.stream({\"query\": \"给我讲一个关于程序员编程的笑话\"}):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ],
   "id": "b92cc5b70a48c277",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 使用 .invoke() ---\n",
      "{'setup': '为什么程序员总是分不清万圣节和圣诞节？', 'punchline': '因为 Oct 31 等于 Dec 25。'}\n",
      "<class 'dict'>\n",
      "\n",
      "--- 使用 .stream() ---\n",
      "```json\n",
      "{\n",
      "  \"setup\": \"为什么程序员总是分不清万圣节和圣诞节？\",\n",
      "  \"punchline\": \"因为 Oct 31 等于 Dec 25\"\n",
      "}\n",
      "```"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#  JsonOutputParser",
   "id": "f1fa336670e020f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T15:08:18.455481Z",
     "start_time": "2025-10-11T15:08:14.041060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 1. 引入依赖包 ---\n",
    "# 这里的pydantic版本为v2\n",
    "import os\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "# --- 2. 使用deepseek模型 ---\n",
    "# 假设 llm 已经定义好\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\", # 截图中为 \"Pro/deepseek-ai/DeepSeek-V3\"，请按需修改\n",
    "    temperature=0,\n",
    "    api_key=os.environ.get(\"DEEPSEEK_API_KEY\"),\n",
    "    # api_base=os.environ.get(\"DEEPSEEK_API_BASE\"), # 如果使用代理，请取消此行注释\n",
    ")\n",
    "\n",
    "# --- 3. 定义用户的查询 ---\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# --- 4. 实例化解析器 ---\n",
    "# 这次我们使用通用的JsonOutputParser\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# --- 5. 创建提示词模板 ---\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# --- 6. 使用LCEL语法组合一个完整的链 ---\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# --- 7. 调用链并打印结果 ---\n",
    "result = chain.invoke({\"query\": joke_query})\n",
    "print(result)\n",
    "\n",
    "# 查看一下返回结果的类型\n",
    "print(type(result))"
   ],
   "id": "11a31d5bf3c5f84e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joke': \"Why don't scientists trust atoms? Because they make up everything.\"}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# XMLOutputParser",
   "id": "bf6dc27f33a23d3a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T15:10:46.067540Z",
     "start_time": "2025-10-11T15:10:28.427834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 1. 引入依赖包 ---\n",
    "import os\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "# --- 2. 使用deepseek模型 ---\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\", # 截图中为 \"Pro/deepseek-ai/DeepSeek-V3\"，请按需修改\n",
    "    temperature=0,\n",
    "    api_key=os.environ.get(\"DEEPSEEK_API_KEY\"),\n",
    ")\n",
    "\n",
    "# --- 3. 定义用户的查询 ---\n",
    "actor_query = \"Generate the shortened filmography for Tom Hanks.\"\n",
    "\n",
    "# --- 4. 实例化XML解析器 ---\n",
    "parser = XMLOutputParser()\n",
    "\n",
    "# (可选) 打印出格式化指令，看看它会告诉LLM什么\n",
    "# print(parser.get_format_instructions())\n",
    "\n",
    "# --- 5. 创建提示词模板 ---\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"{query}\\n{format_instructions}\"\"\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# --- 6. 使用LCEL语法组合一个完整的链 ---\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# --- 7. 调用链并打印结果 ---\n",
    "output = chain.invoke({\"query\": actor_query})\n",
    "print(output)"
   ],
   "id": "7b4db767048e2503",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filmography': [{'actor': [{'name': 'Tom Hanks'}, {'movies': [{'movie': [{'title': 'Splash'}, {'year': '1984'}]}, {'movie': [{'title': 'Big'}, {'year': '1988'}]}, {'movie': [{'title': 'A League of Their Own'}, {'year': '1992'}]}, {'movie': [{'title': 'Philadelphia'}, {'year': '1993'}]}, {'movie': [{'title': 'Forrest Gump'}, {'year': '1994'}]}, {'movie': [{'title': 'Apollo 13'}, {'year': '1995'}]}, {'movie': [{'title': 'Saving Private Ryan'}, {'year': '1998'}]}, {'movie': [{'title': 'Cast Away'}, {'year': '2000'}]}, {'movie': [{'title': 'The Da Vinci Code'}, {'year': '2006'}]}, {'movie': [{'title': 'Captain Phillips'}, {'year': '2013'}]}, {'movie': [{'title': 'Sully'}, {'year': '2016'}]}, {'movie': [{'title': 'A Beautiful Day in the Neighborhood'}, {'year': '2019'}]}, {'movie': [{'title': 'Greyhound'}, {'year': '2020'}]}]}]}]}\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (langchain-learning)",
   "language": "python",
   "name": "langchain-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
